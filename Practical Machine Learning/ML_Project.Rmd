---
title: "JHU Coursera Practical Machine Learning Course Project"
author: "Ricardo J. Serrano"
date: "8/10/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(doParallel)
library(knitr)
theme_set(theme_light())
options(digits = 4)
knitr::opts_chunk$set(fig.height = 4, fig.width = 4, echo = TRUE, message = FALSE)
```

## Introduction

The goal of this project is to predict the manner in which 6 participants are performing different specific exercises from wearable devices accelerometer data. The participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. The data from this project came from this source:  http://groupware.les.inf.puc-rio.br/har.

## Reading the data
```{r}
train_data <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))

test_data <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
```

## Exploratory Data Analysis
```{r}
dim(train_data)
dim(test_data)
str(train_data)
str(test_data)
```

The raw training dataset has 19,622 records with 160 variables (columns). The raw testing has 20 records with the same number of columns. From the str output, there are several variables with NAs or blanks.

Print variables with NAs or blanks ("") percentage greater than 0.8
```{r}
which(colMeans(is.na(train_data) | train_data == "") > 0.8)
```

Let's remove thoses variables. For the training dataset, the first seven variables will be removed, since they are not necessary for the predictive model. In the case of the testing dataset, only the first variable will be discarded.
```{r}
var_remove <- which(colMeans(is.na(train_data) | train_data == "") > 0.8)
train_clean <- train_data[, -var_remove]
train_clean <- train_clean[, -c(1:7)]
test_clean <- test_data[, -var_remove]
test_clean <- test_clean[, -1]
dim(train_clean)
dim(test_clean)
```

The final training dataset has the same records with 53 variables. This data set will be used to create the training and testing datasets for the caret package.

```{r}
set.seed(105)
inTrain <- createDataPartition(y = train_clean$classe, p = 0.8, list = FALSE)
training <- train_clean[inTrain, ]
testing <- train_clean[-inTrain, ]
dim(training)
dim(testing)
```

Configure parallel processing for efficient (and faster) caret execution
```{r}
cl <- makeCluster(detectCores() - 1) # leave 1 core for OS
registerDoParallel(cl)
getDoParWorkers()
```

The classification models chosen are: 
* linear discriminant analysis (lda)
* random forest (ranger)
* gradient boosting machines (gbm)

For the resampling method, the k-cross validation method ("repeatedcv") to reduce sampling bias.

## Train model: linear discriminant analysis (lda)

```{r}
ldaControl <- trainControl(method = "repeatedcv", 
                           number = 5, 
                           repeats = 5, 
                           allowParallel = TRUE)

set.seed(105)
ldafit <- train(classe ~ ., data = training,
                 method = "lda", 
                 trControl = ldaControl)
ldafit
```

Print confusion matrix for lda model
```{r}
pred_lda <- predict(ldafit, newdata = testing)
conf_lda <- confusionMatrix(pred_lda, testing$classe)
conf_lda$table
```

The accuracy of the lda model is around 70%, which is less than satisfactory (model accuracy must be greater than 90%).

## Train model: random forest (rf)

```{r}
rfControl <- trainControl(method = "repeatedcv", 
                           number = 5, 
                           repeats = 5, 
                           allowParallel = TRUE)

set.seed(105)
rf_fit <- train(classe ~ ., data = training,
                 method = "rf", 
                 trControl = rfControl)
rf_fit

plot(rf_fit, main = "Random Forest Accuracy by Number of Predictors")
```

Print confusion matrix for random forest model
```{r}
pred_rf <- predict(rf_fit, newdata = testing)
conf_rf <- confusionMatrix(pred_rf, testing$classe)
conf_rf$table
conf_rf$overall[1]
```

The random forest model overall accuracy is 99.52%, significanlty greater than the linear discriminant analysis model.

Final Model
```{r}
rf_fit$finalModel

varImp(rf_fit)

plot(rf_fit$finalModel, main = "Random Forest Model Error by Number of Trees")
```

The optimal number of predictors as shown in the plot titled "Random Forest Accuracy by Number of Predictors" is 2. There is a slight decrease in the increase number of predictors to 27. After this point, the model accuracy decreases dramatically as the number of predictors increases. In the plot titled "Random Forest Model Error by Number of Trees", the error rate stabilizes after approximately 50 trees, suggesting this number of trees is optimmum.

## Train model: gradient boosted machines (gbm)

```{r}
gbmControl <- trainControl(method = "repeatedcv", 
                           number = 5, 
                           repeats = 5, 
                           allowParallel = TRUE)

set.seed(105)
gbmfit <- train(classe ~ ., data = training, 
                method = "gbm", 
                trControl = gbmControl, 
                verbose = FALSE)
gbmfit

plot(gbmfit, main = "GBM Number of Iterations (first run)")

## model tuning
gbmGrid <-  expand.grid(interaction.depth = c(1, 3, 5, 7), 
                        n.trees = (1:10)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 10)

gbmfit_f <- train(classe ~ ., data = training, 
                method = "gbm", 
                trControl = gbmControl, 
                verbose = FALSE, 
                tuneGrid = gbmGrid)
gbmfit_f

plot(gbmfit_f, main = "GBM Number of Iterations (final)")
```

Print confusion matrix and accuracy for gbm model
```{r}
pred_gbm <- predict(gbmfit_f, newdata = testing)
conf_gbm <- confusionMatrix(pred_gbm, testing$classe)
conf_gbm$table
conf_gbm$overall[1]
```


```{r}
final_pred <- predict(gbmfit_f, newdata = test_clean)
final_pred
```

```{r}
stopCluster(cl)
registerDoSEQ()
```

